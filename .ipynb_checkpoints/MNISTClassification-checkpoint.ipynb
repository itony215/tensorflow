{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tflearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dec6503a2429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmontage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmontage2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tflearn'"
     ]
    }
   ],
   "source": [
    "#importing functions \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage.util.montage import montage2d\n",
    "import tflearn\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#one hot encoding returns an array of zeros and a single one. One corresponds to the class\n",
    "data = input_data.read_data_sets(\"data/MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Shape of images in training dataset {}\".format(data.train.images.shape)\n",
    "print \"Shape of classes in training dataset {}\".format(data.train.labels.shape)\n",
    "print \"Shape of images in testing dataset {}\".format(data.test.images.shape)\n",
    "print \"Shape of classes in testing dataset {}\".format(data.test.labels.shape)\n",
    "print \"Shape of images in validation dataset {}\".format(data.validation.images.shape)\n",
    "print \"Shape of classes in validation dataset {}\".format(data.validation.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample image\n",
    "sample=data.train.images[5].reshape(28,28) \n",
    "plt.imshow(sample ,cmap='gray')\n",
    "plt.title('Sample image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display montage of input data \n",
    "imgs=data.train.images[0:100]\n",
    "montage_img=np.zeros([100,28,28])\n",
    "for i in range(len(imgs)) : \n",
    "        montage_img[i]=imgs[i].reshape(28,28) \n",
    "plt.imshow(montage2d(montage_img), cmap='gray')\n",
    "plt.title('Sample of input data')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images=data.train.images\n",
    "images=np.reshape(images,[images.shape[0],28,28])\n",
    "mean_img = np.mean(images, axis=0)\n",
    "std_img = np.std(images, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mean_img)\n",
    "plt.title('Mean image of the data')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(std_img)\n",
    "plt.colorbar()\n",
    "plt.title('Standard deviation of the data')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input - shape 'None' states that, the value can be anything, i.e we can feed in any number of images\n",
    "#input image\n",
    "x=tf.placeholder(tf.float32,shape=[None,784]) \n",
    "#input class\n",
    "y_=tf.placeholder(tf.float32,shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input Layer\n",
    "\n",
    "#reshaping input for convolutional operation in tensorflow\n",
    "# '-1' states that there is no fixed batch dimension, 28x28(=784) is reshaped from 784 pixels and '1' for a single\n",
    "#channel, i.e a gray scale image\n",
    "x_input=tf.reshape(x,[-1,28,28,1], name='input')\n",
    "#first convolutional layer with 32 output filters, filter size 5x5, stride of 2,same padding, and RELU activation.\n",
    "#please note, I am not adding bias, but one could add bias.Optionally you can add max pooling layer as well \n",
    "conv_layer1=tflearn.layers.conv.conv_2d(x_input, nb_filter=32, filter_size=5, strides=[1,1,1,1],\n",
    "                                        padding='same', activation='relu', regularizer=\"L2\", name='conv_layer_1')\n",
    "\n",
    "#2x2 max pooling layer\n",
    "out_layer1=tflearn.layers.conv.max_pool_2d(conv_layer1, 2)\n",
    "\n",
    "\n",
    "#second convolutional layer \n",
    "conv_layer2=tflearn.layers.conv.conv_2d(out_layer1, nb_filter=32, filter_size=5, strides=[1,1,1,1],\n",
    "                                        padding='same', activation='relu',  regularizer=\"L2\", name='conv_layer_2')\n",
    "out_layer2=tflearn.layers.conv.max_pool_2d(conv_layer2, 2)\n",
    "#fully connected layer\n",
    "fcl= tflearn.layers.core.fully_connected(out_layer2, 1024, activation='relu')\n",
    "fcl_dropout = tflearn.layers.core.dropout(fcl, 0.8)\n",
    "y_predicted = tflearn.layers.core.fully_connected(fcl_dropout, 10, activation='softmax', name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Shape of input : {}\".format(x_input.get_shape().as_list())\n",
    "print \"Shape of first convolutional layer : {}\".format(out_layer1.get_shape().as_list())\n",
    "print \"Shape of second convolutional layer : {}\".format(out_layer2.get_shape().as_list())\n",
    "print \"Shape of fully connected layer : {}\".format(fcl.get_shape().as_list())\n",
    "print \"Shape of output layer : {}\".format(y_predicted.get_shape().as_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss function\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_predicted), reduction_indices=[1]))\n",
    "#optimiser -\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "#calculating accuracy of our model \n",
    "correct_prediction = tf.equal(tf.argmax(y_predicted,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session parameters\n",
    "sess = tf.InteractiveSession()\n",
    "#initialising variables\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session parameters\n",
    "sess = tf.InteractiveSession()\n",
    "#initialising variables\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing the default graph\n",
    "g = tf.get_default_graph()\n",
    "\n",
    "# every operations in our graph\n",
    "[op.name for op in g.get_operations()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing the default graph\n",
    "g = tf.get_default_graph()\n",
    "\n",
    "# every operations in our graph\n",
    "[op.name for op in g.get_operations()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of interations\n",
    "epoch=15000\n",
    "batch_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epoch):\n",
    "    #batch wise training \n",
    "    x_batch, y_batch = data.train.next_batch(batch_size)\n",
    "    _,loss=sess.run([train_step, cross_entropy], feed_dict={x: x_batch,y_: y_batch})\n",
    "    #_, loss,acc=sess.run([train_step,cross_entropy,accuracy], feed_dict={x:input_image , y_: input_class})\n",
    "    \n",
    "    if i%500==0:    \n",
    "        Accuracy=sess.run(accuracy,\n",
    "                           feed_dict={\n",
    "                        x: data.test.images,\n",
    "                        y_: data.test.labels\n",
    "                      })\n",
    "        Accuracy=round(Accuracy*100,2)\n",
    "        print \"Loss : {} , Accuracy on test set : {} %\" .format(loss, Accuracy)\n",
    "    elif i%100==0:\n",
    "        print \"Loss : {}\" .format(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_accuracy=round((sess.run(accuracy,\n",
    "                            feed_dict={\n",
    "                             x: data.validation.images,\n",
    "                             y_: data.validation.labels\n",
    "                              }))*100,2)\n",
    "\n",
    "print \"Accuracy in the validation dataset: {}%\".format(validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_accuracy=round((sess.run(accuracy,\n",
    "                            feed_dict={\n",
    "                             x: data.validation.images,\n",
    "                             y_: data.validation.labels\n",
    "                              }))*100,2)\n",
    "\n",
    "print \"Accuracy in the validation dataset: {}%\".format(validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testset predictions\n",
    "y_test=(sess.run(y_predicted,feed_dict={\n",
    "                             x: data.test.images\n",
    "                              }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "true_class=np.argmax(data.test.labels,1)\n",
    "predicted_class=np.argmax(y_test,1)\n",
    "cm=confusion_matrix(predicted_class,true_class)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting confusion Matrix\n",
    "plt.imshow(cm,interpolation='nearest')\n",
    "plt.colorbar()\n",
    "number_of_class=len(np.unique(true_class))\n",
    "tick_marks = np.arange(len(np.unique(true_class)))\n",
    "plt.xticks(tick_marks, range(number_of_class))\n",
    "plt.yticks(tick_marks, range(number_of_class))\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding error outputs\n",
    "idx=np.argmax(y_test,1)==np.argmax(data.test.labels,1) \n",
    "cmp=np.where(idx==False) #indices of error outputs\n",
    "# plotting errors\n",
    "fig, axes = plt.subplots(5, 3, figsize=(15,15))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "cls_true=np.argmax(data.test.labels,1)[cmp]\n",
    "cls_pred=np.argmax(y_test,1)[cmp]\n",
    "images=data.test.images[cmp]\n",
    "for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i].reshape(28,28), cmap='binary')\n",
    "        xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])      \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer1_filters=conv_layer1.W.eval()\n",
    "print conv_layer1_filters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer1_filters_img=conv_layer1_filters[:,:,0,:]\n",
    "print conv_layer1_filters_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting filters of the first convolutional layer\n",
    "fig, axes = plt.subplots(8, 4, figsize=(15,15))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(conv_layer1_filters_img[:,:,i], cmap='gray')\n",
    "        xlabel = \"Filter : {}\".format(i+1)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image=np.reshape(data.test.images[0], [1,784])\n",
    "conv_layer1_output=(sess.run(out_layer1,\n",
    "               feed_dict={\n",
    "                   x:test_image\n",
    "               }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(data.test.images[0], [28,28]), cmap='gray')\n",
    "plt.title('Test Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print conv_layer1_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_layer1_output_img=conv_layer1_output[0,:,:,:]\n",
    "fig, axes = plt.subplots(8, 4, figsize=(15,15))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(conv_layer1_output_img[:,:,i], cmap='gray')\n",
    "        xlabel = \"Filter : {}\".format(i+1)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])      \n",
    "fig.suptitle('Output of the first convolutional layer')  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
